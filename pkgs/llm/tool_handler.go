package llm

import (
	"config"
	"context"
	"encoding/json"
	"fmt"
	"mcp"
	log "mylog"
	"net/http"
	"net/url"
	"strings"
)

// ToolExecutor handles tool call execution loop
type ToolExecutor struct {
	account        string
	maxCalls       int
	availableTools []mcp.LLMTool
	writer         http.ResponseWriter
	flusher        http.Flusher
}

// NewToolExecutor creates a new tool executor
func NewToolExecutor(account string, tools []mcp.LLMTool, w http.ResponseWriter, flusher http.Flusher) *ToolExecutor {
	return &ToolExecutor{
		account:        account,
		maxCalls:       25,
		availableTools: tools,
		writer:         w,
		flusher:        flusher,
	}
}

// ExecuteToolLoop executes the main tool calling loop
func (te *ToolExecutor) ExecuteToolLoop(query string, selectedTools []string) error {
	log.DebugF(log.ModuleLLM, "=== Streaming LLM Processing Started with Tool Support ===")
	log.DebugF(log.ModuleLLM, "Query: account=%s %s", te.account, query)
	log.DebugF(log.ModuleLLM, "Selected tools: %v", selectedTools)

	maxSelected := GetMaxSelectedTools()
	if len(selectedTools) > maxSelected {
		log.WarnF(log.ModuleLLM, "Selected tools count is too large, max is %d", maxSelected)
		selectedTools = selectedTools[:maxSelected]
	}

	sysPrompt := BuildEnhancedSystemPrompt(te.account)

	// Initialize messages
	messages := []Message{
		{
			Role:    "system",
			Content: sysPrompt,
		},
		{
			Role:    "user",
			Content: query,
		},
	}

	// Get available tools
	availableTools := mcp.GetAvailableLLMTools(selectedTools)
	log.DebugF(log.ModuleLLM, "Available LLM tools: %d", len(availableTools))

	// ========== Phase 1: æ™ºèƒ½å·¥å…·è·¯ç”±ï¼ˆå½“å·¥å…·æ•° > 15 æ—¶å¯ç”¨ï¼‰ ==========
	if len(availableTools) > 15 {
		routedTools := te.routeTools(query, availableTools)
		if len(routedTools) > 0 {
			availableTools = routedTools
			log.MessageF(log.ModuleLLM, "[å·¥å…·è·¯ç”±] ä»Ž %d ä¸ªå·¥å…·ä¸­ç­›é€‰å‡º %d ä¸ªç›¸å…³å·¥å…·", len(mcp.GetAvailableLLMTools(selectedTools)), len(availableTools))
		}
	}

	var fullResponse strings.Builder
	var toolCallLog []string // è·Ÿè¸ªæœ¬è½®è°ƒç”¨çš„å·¥å…·

	// åœ¨èŠå¤©æµä¸­æ˜¾ç¤ºæœ¬æ¬¡ä½¿ç”¨çš„å·¥å…·æ•°é‡
	toolCountMsg := fmt.Sprintf("[ðŸ”§ æœ¬æ¬¡åŠ è½½ %d ä¸ªå·¥å…·]", len(availableTools))
	fmt.Fprintf(te.writer, "data: %s\n\n", url.QueryEscape(toolCountMsg))
	te.flusher.Flush()

	// Initial LLM call
	_, toolCalls, err := SendStreamingLLMRequest(messages, availableTools, te.writer, te.flusher, &fullResponse)
	if err != nil {
		log.ErrorF(log.ModuleLLM, "Initial streaming LLM request failed: %v", err)
		return fmt.Errorf("initial streaming LLM request failed: %v", err)
	}

	// Tool calling loop with max iterations
	maxCall := te.maxCalls
	for len(toolCalls) > 0 && maxCall > 0 {
		maxCall--
		log.DebugF(log.ModuleLLM, "Tool calling iteration, remaining: %d", maxCall)

		// Process tool calls
		log.DebugF(log.ModuleLLM, "Processing %d tool calls", len(toolCalls))
		for _, toolCall := range toolCalls {
			// Log tool call status but don't send to client to keep response clean
			log.DebugF(log.ModuleLLM, fmt.Sprintf("\n[Calling tool %s with args %s]\n", toolCall.Function.Name, toolCall.Function.Arguments))

			toolName := toolCall.Function.Name
			toolArgs := make(map[string]interface{})
			toolCallLog = append(toolCallLog, toolName)

			fmt.Fprintf(te.writer, "data: %s\n\n", url.QueryEscape(fmt.Sprintf("[Calling tool %s with args %s]", toolCall.Function.Name, toolCall.Function.Arguments)))
			te.flusher.Flush()

			// Parse tool arguments with validation
			if toolCall.Function.Arguments == "" {
				log.WarnF(log.ModuleLLM, "Tool call %s has empty arguments, skipping", toolName)
				continue
			}

			// Validate JSON format first
			if !IsValidJSON(toolCall.Function.Arguments) {
				log.ErrorF(log.ModuleLLM, "Tool call %s has invalid JSON arguments: %s", toolName, toolCall.Function.Arguments)
				continue
			}

			if err := json.Unmarshal([]byte(toolCall.Function.Arguments), &toolArgs); err != nil {
				log.ErrorF(log.ModuleLLM, "Failed to parse tool arguments for %s: %v, args: %s", toolName, err, toolCall.Function.Arguments)
				continue
			}

			// Call the tool
			log.InfoF(log.ModuleLLM, "Tool call begin: %s %v", toolName, toolArgs)
			result := mcp.CallMCPTool(toolName, toolArgs)
			log.InfoF(log.ModuleLLM, "Tool call result: %s %v %v", toolName, toolArgs, result)

			// Add tool call and result to message history
			messages = append(messages, Message{
				Role:      "assistant",
				ToolCalls: []mcp.ToolCall{SanitizeToolCall(toolCall)},
			})

			toolContent := TruncateString(fmt.Sprintf("%v", result.Result), MaxToolResultChars)
			messages = append(messages, Message{
				Role:       "tool",
				ToolCallId: toolCall.ID,
				Content:    toolContent,
			})

			// Add tool call info to full response for saving
			save := config.GetConfigWithAccount(config.GetAdminAccount(), "assistant_save_mcp_result")
			// len(result.Result) < 32 indicates short result, not privacy data, can be stored in Assistant_xxx
			if strings.ToLower(save) == "true" || len(fmt.Sprintf("%v", result.Result)) < 32 {
				fullResponse.WriteString(fmt.Sprintf("\n[Tool %s called with result: %v]\n", toolName, result.Result))
			} else {
				// Don't display tool callback returned data, involves privacy, sending to LLM is fine, but caching and displaying on UI is problematic
				fullResponse.WriteString(fmt.Sprintf("\n[Tool %s called with result: %s]\n", toolName, "###$#&$#*$)@$&$%&$())!@###"))
			}
		}

		// Next LLM call with updated messages
		log.InfoF(log.ModuleLLM, "Tool calls processed, sending next LLM request")
		// ä¸Šä¸‹æ–‡åŽ‹ç¼©ï¼šå½“æ¶ˆæ¯è¿‡é•¿æ—¶åŽ‹ç¼©æ—§æ¶ˆæ¯ï¼ˆå‚è€ƒ Anthropic Compactionï¼‰
		messages = CompactMessages(messages, te.account)
		_, toolCalls, err = SendStreamingLLMRequest(messages, availableTools, te.writer, te.flusher, &fullResponse)
		if err != nil {
			log.ErrorF(log.ModuleLLM, "LLM call failed in tool loop: %v", err)
			break
		}
		log.InfoF(log.ModuleLLM, "Next LLM response received, tool calls: %d", len(toolCalls))
	}

	// Send completion signal to client
	log.DebugF(log.ModuleLLM, "Tool processing complete, sending DONE signal")
	fmt.Fprintf(te.writer, "data: [DONE]\n\n")
	te.flusher.Flush()

	// Save complete response to diary
	go SaveLLMResponseToDiary(te.account, query, fullResponse.String())
	// Save structured session progress for cross-session memory
	go SaveSessionProgress(te.account, query, fullResponse.String(), toolCallLog)
	return nil
}

// ProcessQueryStreaming is a convenience function wrapping ToolExecutor
func ProcessQueryStreaming(account string, query string, selectedTools []string, w http.ResponseWriter, flusher http.Flusher) error {
	executor := NewToolExecutor(account, nil, w, flusher)
	return executor.ExecuteToolLoop(query, selectedTools)
}

// routeTools å·¥å…·è·¯ç”±ï¼šç”¨ LLM ä»Žå·¥å…·ç›®å½•ä¸­ç­›é€‰ä¸Žç”¨æˆ·é—®é¢˜ç›¸å…³çš„å·¥å…·
func (te *ToolExecutor) routeTools(query string, allTools []mcp.LLMTool) []mcp.LLMTool {
	// æž„å»ºå·¥å…·ç›®å½•ï¼ˆä»… name + descriptionï¼Œä¸å«å‚æ•° schemaï¼ŒèŠ‚çœ tokenï¼‰
	var catalog strings.Builder
	toolMap := make(map[string]mcp.LLMTool, len(allTools))
	for i, tool := range allTools {
		catalog.WriteString(fmt.Sprintf("%d. %s: %s\n", i+1, tool.Function.Name, tool.Function.Description))
		toolMap[tool.Function.Name] = tool
	}

	routePrompt := fmt.Sprintf(`ä½ æ˜¯ä¸€ä¸ªå·¥å…·è·¯ç”±å™¨ã€‚æ ¹æ®ç”¨æˆ·çš„é—®é¢˜ï¼Œä»Žä»¥ä¸‹å·¥å…·ç›®å½•ä¸­é€‰æ‹©æ‰€æœ‰å¯èƒ½éœ€è¦ç”¨åˆ°çš„å·¥å…·ã€‚

ç”¨æˆ·é—®é¢˜: %s

å·¥å…·ç›®å½•:
%s
é€‰æ‹©è§„åˆ™ï¼š
1. å®å¤šå‹¿å°‘ï¼ŒæŠŠæ‰€æœ‰å¯èƒ½ç›¸å…³çš„å·¥å…·éƒ½é€‰ä¸Š
2. å¦‚æžœä»»åŠ¡éœ€è¦æ—¥æœŸä¿¡æ¯ï¼Œå¿…é¡»åŒ…å« RawCurrentDate
3. å¦‚æžœæ¶‰åŠæŸ¥è¯¢æ•°æ®ï¼ŒåŒæ—¶é€‰æ‹©èŽ·å–æ•°æ®çš„å·¥å…·å’Œå¯èƒ½éœ€è¦çš„è¾…åŠ©å·¥å…·
4. åªè¿”å›žJSONæ•°ç»„ï¼Œä¸è¦å…¶ä»–æ–‡å­—

ç¤ºä¾‹: ["RawCurrentDate", "RawGetExerciseByDateRange"]
å¦‚æžœä¸éœ€è¦ä»»ä½•å·¥å…·ï¼Œè¿”å›ž []`, query, catalog.String())

	routeMessages := []Message{
		{Role: "user", Content: routePrompt},
	}

	resp, err := SendSyncLLMRequestNoTools(context.Background(), routeMessages, te.account)
	if err != nil {
		log.WarnF(log.ModuleLLM, "[å·¥å…·è·¯ç”±] LLM è°ƒç”¨å¤±è´¥: %v, ä½¿ç”¨å…¨éƒ¨å·¥å…·", err)
		return nil // fallback åˆ°å…¨éƒ¨å·¥å…·
	}

	// è§£æž JSON æ•°ç»„
	resp = strings.TrimSpace(resp)
	// åŽ»æŽ‰å¯èƒ½çš„ markdown ä»£ç å—åŒ…è£¹
	resp = strings.TrimPrefix(resp, "```json")
	resp = strings.TrimPrefix(resp, "```")
	resp = strings.TrimSuffix(resp, "```")
	resp = strings.TrimSpace(resp)

	var toolNames []string
	if err := json.Unmarshal([]byte(resp), &toolNames); err != nil {
		log.WarnF(log.ModuleLLM, "[å·¥å…·è·¯ç”±] è§£æžå¤±è´¥: %v, åŽŸå§‹å“åº”: %s", err, resp)
		return nil // fallback åˆ°å…¨éƒ¨å·¥å…·
	}

	if len(toolNames) == 0 {
		log.MessageF(log.ModuleLLM, "[å·¥å…·è·¯ç”±] LLM åˆ¤æ–­æ— éœ€å·¥å…·")
		return []mcp.LLMTool{} // è¿”å›žç©ºï¼Œè®© LLM ç›´æŽ¥å›žç­”
	}

	// ç­›é€‰å‡ºå¯¹åº”çš„å®Œæ•´å·¥å…·å®šä¹‰
	var selected []mcp.LLMTool
	for _, name := range toolNames {
		if tool, ok := toolMap[name]; ok {
			selected = append(selected, tool)
		}
	}

	if len(selected) == 0 {
		log.WarnF(log.ModuleLLM, "[å·¥å…·è·¯ç”±] æœªåŒ¹é…åˆ°ä»»ä½•å·¥å…·ï¼Œä½¿ç”¨å…¨éƒ¨å·¥å…·")
		return nil
	}

	log.MessageF(log.ModuleLLM, "[å·¥å…·è·¯ç”±] é€‰ä¸­å·¥å…·: %v", toolNames)
	return selected
}
